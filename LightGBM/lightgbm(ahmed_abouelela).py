# -*- coding: utf-8 -*-
"""LightGBM(Ahmed Abouelela).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14OoUkvI13tSW3s3pYpX0iqm3t9GRHKdE
"""

from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFECV
import pandas as pd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
import plotly.figure_factory as ff
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import f_classif
from sklearn.ensemble import GradientBoostingClassifier
pio.renderers.default = 'colab'

!pip install artemis

!pip install pyartemis

"""# **Loading Data and Preprocessing**"""

data = load_breast_cancer()

print(f"Dataset shape: {data.data.shape}")
print(f"Target names: {data.target_names}")

feature_names = data.feature_names
target_names = data.target_names
df = pd.DataFrame(data.data, columns=feature_names)
df['target'] = data.target
print(df.head())

df

print(df.isnull().sum())

X = df.drop('target', axis=1)
y = df['target']

"""# **Standardization**"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

"""# **Splitting**"""

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

df.shape

len(data.feature_names)

y.value_counts(normalize=True)

X_train.shape

X_test.shape

df.duplicated().sum()

features = df.drop('target', axis=1)

selected_features=['mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']

X_df = pd.DataFrame(X, columns=data.feature_names)

X_train_df =  pd.DataFrame(X_train, columns=data.feature_names)

"""# **LIGHT GBM**"""

import lightgbm as lgb

lgb = lgb.LGBMClassifier()
lgb.fit(X_train, y_train)

lgb_pred = lgb.predict(X_test)

print("Accuracy:", accuracy_score(y_test, lgb_pred))
print(classification_report(y_test, lgb_pred))

"""# **Confusion Matrix**"""

print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_test, lgb_pred)
print(conf_matrix)

labels = ['Benign', 'Malignant']
fig = ff.create_annotated_heatmap(
    z=conf_matrix,
    x=labels,
    y=labels,
    colorscale='Viridis',
    showscale=True,
    annotation_text=[[str(value) for value in row] for row in conf_matrix]
)


fig.update_layout(
    title="Confusion Matrix",
    xaxis_title="Predicted Label",
    yaxis_title="True Label",
    width=600,
    height=600
)


fig.show()

"""##Confusion matrix shows a classification model with 39 true benign predictions, 71 true malignant predictions, 1 false benign, and 3 false malignant cases, showing high accuracy when predicting malignant predictions

# **Learning Curve**
"""

import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import learning_curve
import numpy as np
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)




train_sizes = [1, 75, 150, 270, 331]


train_sizes, train_scores, test_scores = learning_curve(
    estimator=lgb,
    X=X_train_scaled,
    y=y_train,
    cv=5,
    scoring="accuracy",
    train_sizes=train_sizes
)


train_mean = np.mean(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)


plt.subplots(figsize=(10, 8))
plt.plot(train_sizes, train_mean, label="Train")
plt.plot(train_sizes, test_mean, label="Validation")


plt.title("Learning Curve for Light GBM", fontsize=14)
plt.xlabel("Training Set Size", fontsize=12)
plt.ylabel("Accuracy", fontsize=12)
plt.legend(loc="best")

plt.show()

"""##The LightGBM training curve shows training accuracy constant at 1.0, validation accuracy rising from 0.94 to 0.97 with a peak when the number of training set size is approximately 200, which indicate good generalization

# **Validation curve**
"""

from sklearn.model_selection import validation_curve

def plot_validation_curve(estimator, title, X, y, param_name, param_range, cv=5, scoring="accuracy"):
    train_scores, test_scores = validation_curve(
        estimator=estimator,
        X=X,
        y=y,
        param_name=param_name,
        param_range=param_range,
        cv=cv,
        scoring=scoring
    )

    train_mean = np.mean(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(param_range, train_mean, label="Training score", color="blue")
    plt.plot(param_range, test_mean, label="Cross-validation score", color="red")

    plt.title(title)
    plt.xlabel(param_name)
    plt.ylabel("Accuracy")
    plt.legend(loc="best")
    plt.grid()
    plt.show()



param_range = np.arange(1, 21)
plot_validation_curve(
    lgb,
    "Validation Curve for Light GBM",
    X_train_scaled,
    y_train,
    "max_depth",
    param_range,
    cv=5,
    scoring="accuracy"
)

"""##The LightGBM validation curve shows the training score constant at 1.0, while the cross-validation score is at a peak at 0.980 for max_depth of 6.5 and drops to 0.975 for max_depth  10, showing overfitting when tree depth is higher.

# **Precision-Recall Curve**
"""

from sklearn.metrics import precision_recall_curve
y_probs_lgb = lgb.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_probs_lgb)

plt.figure(figsize=(8, 6))
plt.plot(recall, precision, marker=".", label="Light GBM Classifier")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend()
plt.grid()
plt.show()

"""##LightGBM Classifier precision-recall curve is have high precision 1.0 for up to a recall of  0.95 before it drops significantly to 0.65, indicates excellent performance for most positive predictions

# **ROC Curve**
"""

from sklearn.metrics import roc_curve, auc
fpr, tpr, thresholds = roc_curve(y_test, y_probs_lgb)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--", label="Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic (ROC) Curve")
plt.legend(loc="lower right")
plt.grid()
plt.show()

"""##ROC curve shows a high Area Under the Curve  of 0.99, with a near-perfect True Positive Rate and very low False Positive Rate compared to random guess, indicates high classification performance"""

!pip install eli5

import eli5
from eli5.sklearn import PermutationImportance

print("\nELI5 Explanation for Light GBM:")
display(eli5.show_weights(lgb, feature_names=X.columns.tolist()))

"""##The ELI5 Explanation of LightGBM shows worst_perimeter (0.2362) as the most importan feature on the model predictions, followed by worst_concave_points and worst_radius , where as features like mean_compactness have very little impact."""

print("\nELI5 Explanation for Light GBM with Permutation Importance :")
perm = PermutationImportance(lgb, random_state=42).fit(X_test, y_test)
display(eli5.show_weights(perm, feature_names=X.columns.tolist()))

"""##ELI5  of LightGBM with Permutation Importance shows the most important feature to the model predictions as worst_concave_points , followed by worst_texture , while other features like radius_error and worst_fractal_dimension are not important"""

eli5.show_prediction(lgb, X_test.iloc[1], horizontal_layout=False, show_feature_values=True)

"""##The ELI5 Pridection LightGBM y=1, probability 1.000, score 10.922 shows that worst_concave_points is the most positive contributor to the prediction, followed by worst_perimeter, while compactness_error is the least.

# **PDP**
"""

from sklearn.inspection import PartialDependenceDisplay

feature = [3]

target_class = 1

PartialDependenceDisplay.from_estimator(lgb, X_test, features=feature, target=target_class)
plt.show()

"""##The Partial Dependence Plot shows the mean_area feature decreases in partial dependence from 0.645 to 0.630 at about a value of 0.0, indicares a strong negative impact on the model's predictions

# **ICE**
"""

PartialDependenceDisplay.from_estimator(lgb, X_test, features=feature, target=target_class, kind='individual')
plt.title("ICE - Light GBM")
plt.show()

"""##The ICE plot for LightGBM shows that the mean_area feature have  a large drop in partial dependence from about 0.9 to 0.1 at around a value of 0.0 for the most of instances, with a strong negative effect on the model's predictions as mean_area increases

# **ALE**
"""

!pip install alibi

from alibi.explainers import ALE, plot_ale

proba_fun_lgb = lgb.predict_proba

proba_ale_lgb = ALE(proba_fun_lgb, feature_names=feature_names, target_names=target_names)

proba_exp_lgb = proba_ale_lgb.explain(X_train.values)

plot_ale(proba_exp_lgb, features=selected_features, n_cols=5, fig_kw={'figwidth': 15, 'figheight': 10})

"""##ALE plots of the GradientBoosting model shows that features like worst_concave_points,worst_area, and worst_radius have strong negative impacts on prediction

# **Permutation Feature Importance**
"""

from sklearn.inspection import permutation_importance

result = permutation_importance(lgb, X_test, y_test, n_repeats=10, random_state=42)
sorted_idx = result.importances_mean.argsort()

plt.barh(X_df.columns[sorted_idx], result.importances_mean[sorted_idx])
plt.title("Permutation Feature Importance - Light GBM")
plt.show()

"""##The Permutation Feature Importance for LightGBM shows that  worst_concave_points  is  the most significant feature, with worst_texture and mean_texture, and  a  negative importance of worst_symmetry  reflecting their relative impact to model predictions

# **LOFO**
"""

from sklearn.model_selection import cross_val_score

baseline = cross_val_score(lgb, X_train, y_train, cv=5).mean()

lofo_scores = {}
for col in X_df.columns:
    X_lofo = X_train_df.drop(columns=[col])
    score = cross_val_score(lgb, X_lofo, y_train, cv=5).mean()
    lofo_scores[col] = baseline - score

lofo_df = pd.Series(lofo_scores).sort_values(ascending=False)
lofo_df.plot(kind='barh')
plt.title("LOFO Importance - GradientBoosting")
plt.show()

"""##The LOFO Importance for GradientBoosting shows that compactness_error  is the most significant feature, followed by mean_smoothness and worst_concavity , and mean_texture has a negative importance , indicating their impact on model predictions

# **Global Surrogate**
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import r2_score

surrogate = DecisionTreeClassifier(max_depth=3)
lgb_preds = lgb.predict(X_train)
surrogate.fit(X_train, lgb_preds)

from sklearn import tree
plt.figure(figsize=(12,6))
tree.plot_tree(surrogate, feature_names=X_df.columns, filled=True)
plt.title("Global Surrogate Tree -  Light GBM")
plt.show()

"""##The Global Surrogate Tree for LightGBM splits primarily on worst_radius , worst_concave_points , and texture_error, with high purity at the leaves

# **H-statistic**
"""

from artemis.interactions_methods.model_agnostic import FriedmanHStatisticMethod
import random

random.seed(8)

X_exp = random.choices(X_train.values.tolist(), k=100)
X_exp_df = pd.DataFrame(X_exp, columns=feature_names)


X_exp_scaled = scaler.transform(X_exp_df)


X_exp_scaled_df = pd.DataFrame(X_exp_scaled, columns=feature_names)


h_stat = FriedmanHStatisticMethod()
h_stat.fit(lgb, X_exp_scaled_df)

# Overall interaction plot
fig, ax = plt.subplots(figsize=(10, 4))
h_stat.plot('bar_chart_ova',ax=ax)

"""##The interaction with all other features  chart  shows that worst_texture  has the highest Friedman H-statistic interaction with all other features in the GradientBoosting model, then worst_smoothness and mean_texture , indicates strong feature interactions, while worst_symmetry has the lowest interaction"""

# Pairwise interactions
fig, ax = plt.subplots(figsize=(10, 4))
h_stat.plot(vis_type='bar_chart',ax=ax)

"""##The pair interactions chart shows that The greatest Friedman H-statistic interaction between worst_perimeter and worst_concave_points , then mean_concave_points and worst_concave_points , since these pairs of features contribute most to the GradientBoosting model's predictions"""

# Interaction heatmap
h_stat.plot()

"""##The interaction matrix for the GradientBoosting model highlights the strongest Friedman H-statistic interactions between worst_concave_points and worst_perimeter"""

!pip install lime

!pip install shap

"""# **LIME**"""

import lime
import lime.lime_tabular

explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=np.array(X_train_scaled),
    feature_names=feature_names.tolist(),
    class_names=['malignant', 'benign'],
    mode='classification',
    discretize_continuous=True
)

i = 0
exp = explainer.explain_instance(
    data_row=X_test_scaled[i],
    predict_fn=lgb.predict_proba,
    num_features=len(feature_names)
)


exp.show_in_notebook(show_table=True, show_all=False)

"""##The LIME model explaination for the LightGBM malignant prediction probability= 1.00 highlights worst_concave_points  as the most strong positive feature , then worst_perimeter ,and mean_symmetry is the least

# **SHAP**
"""

import shap
import matplotlib.pyplot as plt


background_data = shap.sample(X_train_scaled, 100)


explainer = shap.TreeExplainer(lgb)


shap_values = explainer.shap_values(X_test_scaled)


plt.figure()
shap.summary_plot(shap_values[:, :], X_test_scaled, feature_names=feature_names, show=True)
plt.show()

"""##The SHAP plot of the LightGBM model shows worst_perimeter and worst_concave_points as the most important features"""

plt.figure()
shap.summary_plot(shap_values[:, :], X_test_scaled, feature_names=feature_names, plot_type="bar", show=True)
plt.close()

"""##The SHAP  bar plot of the LightGBM model shows worst_perimeter , worst_concave_points, and worst_area  are the most imactful features , others features like perimeter_error have little impact"""

explanation = shap.Explanation(
    values=shap_values,
    base_values=explainer.expected_value,
    data=X_test_scaled,
    feature_names=feature_names
)

num_features = len(feature_names)

# Bar plot for global feature importance
plt.figure()
shap.plots.bar(explanation, max_display=num_features, show=True)
plt.close()

"""##The SHAP global feature importance bar plot of  LightGBM  shows that worst_perimeter (+1.48) and worst_concave_points (+1.39) are the most important features enhancing the prediction, while mean_radius and mean_symmetry (+0.01) have no impact."""

plt.figure()
shap.plots.waterfall(explanation[0], max_display=num_features, show=True)
plt.close()

plt.figure()
shap.plots.waterfall(explanation[1], max_display=num_features, show=True)
plt.close()

plt.figure()
shap.plots.heatmap(explanation, max_display=num_features, show=True)
plt.close()

"""##The SHAP heatmap plot for the LightGBM model shows worst_perimeter and worst_concave_points as the top contributors  to the model's output over instances"""