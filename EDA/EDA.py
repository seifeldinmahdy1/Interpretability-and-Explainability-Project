# -*- coding: utf-8 -*-
"""XAI_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GFzpp3_4ssAQUviryMg_w7-gTAX7cV5I

# Importing Neccessary Libraries
"""

from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFECV
import pandas as pd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import f_classif
pio.renderers.default = 'colab'

"""#Loading Data and Preprocessing"""

data = load_breast_cancer()

print(f"Dataset shape: {data.data.shape}")
print(f"Target names: {data.target_names}")

feature_names = data.feature_names
df = pd.DataFrame(data.data, columns=feature_names)
df['target'] = data.target
print(df.head())

df

print(df.isnull().sum())

X = df.drop('target', axis=1)
y = df['target']

"""## Standardization"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

"""## Splitting"""

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

df.shape

len(data.feature_names)

y.value_counts(normalize=True)

X_train.shape

X_test.shape

df.duplicated().sum()

features = df.drop('target', axis=1)

"""# EDA

## Outlier Detection by IQR & Z-score
"""

def detect_outliers_iqr(data):
    outliers_dict = {}
    for column in data.columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)][column]
        outliers_dict[column] = {
            'count': len(outliers),
            'outlier_indices': outliers.index.tolist()
        }
    return outliers_dict

def detect_outliers_zscore(data, threshold=3):
    outliers_dict = {}
    for column in data.columns:
        z_scores = np.abs((data[column] - data[column].mean()) / data[column].std())
        outliers = data[z_scores > threshold][column]
        outliers_dict[column] = {
            'count': len(outliers),
            'outlier_indices': outliers.index.tolist()
        }
    return outliers_dict

iqr_outliers = detect_outliers_iqr(features)
total_iqr_outliers = sum(info['count'] for info in iqr_outliers.values())
total_iqr_outliers

zscore_outliers = detect_outliers_zscore(features, threshold=3)
total_zscore_outliers = sum(info['count'] for info in zscore_outliers.values())
total_zscore_outliers

numerical_features = df.select_dtypes(include='number').columns

for feature in numerical_features:
    fig = px.box(
        df,
        x='target',
        y=feature,
        color='target',
        title=f'Boxplot of {feature} by Diagnosis',
        labels={'target': 'Diagnosis', feature: feature}
    )
    fig.show()

"""Since this is a diagnostic dataset, it would be better to keep the outliers as they may be clinically meaningful, and malignant tumors often have more extreme feature values. example: mean radius, worst area, etc."""

df.dtypes

df.dtypes.value_counts()

"""There is no need to convert data types as all models handle int64 and float64 types, and there are no object types"""

stats = features.agg(['mean', 'std', 'min', 'max']).T.round(2)
stats.head(6)

print(f"Mean Skewness: {features.skew().mean():.2f}, Range: {features.skew().min():.2f} to {features.skew().max():.2f}")

"""## Some Features Distripution"""

selected_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',
                    'mean smoothness', 'worst area']

fig = make_subplots(rows=2, cols=3, subplot_titles=selected_features)
for i, col in enumerate(selected_features):
    row = i // 3 + 1
    col_pos = i % 3 + 1
    fig.add_trace(
        go.Histogram(x=features[col], nbinsx=20, name=col, showlegend=False),
        row=row, col=col_pos
    )
fig.update_layout(
    height=600, width=900, title_text="Feature Distributions",
    title_font_size=14, bargap=0.1
)
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False, title_text="")
fig.show()

target_counts = df['target'].value_counts()
target_percent = df['target'].value_counts(normalize=True) * 100
dist_df = pd.DataFrame({
    'Count': target_counts,
    'Percentage': target_percent.round(2)
})
dist_df.index = ['Benign (1)', 'Malignant (0)']
dist_df

"""## Target Distripution"""

fig_target = go.Figure(data=[
    go.Bar(
        x=['Benign (1)', 'Malignant (0)'],
        y=target_counts.values,
        marker_color=['#FF9999', '#66CC99']
    )
])
fig_target.update_layout(
    height=400, width=600, title_text="Target Distribution",
    title_font_size=14, xaxis_title="", yaxis_title="Count",
    bargap=0.2
)
fig_target.show()

"""## Radius Mean Distrupution between benign and malignant"""

m_values = data.data[data.target == 0][:, 0]
b_values = data.data[data.target == 1][:, 0]

m_hist, m_bins = np.histogram(m_values, bins=30)
b_hist, b_bins = np.histogram(b_values, bins=30)

frequent_malignant_radius_mean = m_hist.max()
index_frequent_malignant_radius_mean = list(m_hist).index(frequent_malignant_radius_mean)
most_frequent_malignant_radius_mean = m_bins[index_frequent_malignant_radius_mean]

print("Most frequent malignant radius mean is:", most_frequent_malignant_radius_mean)

fig = go.Figure()

fig.add_trace(go.Histogram(
    x=m_values,
    nbinsx=30,
    name='Malignant',
    marker_color='red',
    opacity=0.5
))

fig.add_trace(go.Histogram(
    x=b_values,
    nbinsx=30,
    name='Benign',
    marker_color='green',
    opacity=0.5
))

fig.update_layout(
    barmode='overlay',
    title='Histogram of Radius Mean for Benign and Malignant Tumors',
    xaxis_title='Radius Mean Values',
    yaxis_title='Frequency',
    legend_title='Diagnosis'
)

fig.show()

fig = px.scatter(
    df,
    x='worst concavity',
    y='worst concave points',
    trendline='ols',
    title='Joint Plot of Concavity Worst vs Concave Points Worst',
    marginal_x='histogram',
    marginal_y='histogram'
)

fig.update_layout(
    xaxis_title='worst concavity',
    yaxis_title='worst concave points'
)

fig.show()

"""## Bivariate Analysis: Pairplots for selected features"""

selected_features_pairplot = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness']
fig_pairplot = px.scatter_matrix(df, dimensions=selected_features_pairplot, color='target', title='Pairplot of Selected Features')
fig_pairplot.update_traces(diagonal_visible=False)
fig_pairplot.show()

"""## Multivariate Analysis: 3D scatter plot with target as color"""

fig_3d = px.scatter_3d(df, x='mean radius', y='mean texture', z='mean perimeter', color='target', title='3D Scatter Plot')
fig_3d.show()

corr_matrix = features.corr()
fig_heatmap = px.imshow(corr_matrix, color_continuous_scale='RdBu_r', title="Correlation Matrix Heatmap")
fig_heatmap.update_layout(width=1000, height=800)
fig_heatmap.show()

"""From the heatmap, we can observe from the heatmaps that there are many negative correlations between the numerical variables in this dataset.

### Positive correlated features
"""

def plot_feat1_feat2(feat1, feat2):
    M = df[df['target'] == 0]
    B = df[df['target'] == 1]

    trace0 = go.Scatter(
        x=M[feat1],
        y=M[feat2],
        name='malignant',
        mode='markers',
        marker=dict(
            color='#FFD700',
            line=dict(width=1)
        )
    )

    trace1 = go.Scatter(
        x=B[feat1],
        y=B[feat2],
        name='benign',
        mode='markers',
        marker=dict(
            color='#7EC0EE',
            line=dict(width=1)
        )
    )

    layout = dict(
        title=feat1 + " " + "vs" + " " + feat2,
        yaxis=dict(title=feat2, zeroline=False),
        xaxis=dict(title=feat1, zeroline=False)
    )

    plots = [trace0, trace1]

    fig = dict(data=plots, layout=layout)
    pio.show(fig)

plot_feat1_feat2('mean perimeter', 'worst radius')
plot_feat1_feat2('mean area', 'worst radius')
plot_feat1_feat2('mean texture', 'worst texture')
plot_feat1_feat2('worst area', 'worst radius')

"""### Uncorrelated features"""

plot_feat1_feat2('mean smoothness','mean texture')
plot_feat1_feat2('mean radius','worst fractal dimension')
plot_feat1_feat2('mean texture','mean symmetry')
plot_feat1_feat2('mean texture','symmetry error')

"""### Negative correlated features"""

plot_feat1_feat2('mean area','worst fractal dimension')
plot_feat1_feat2('mean radius','worst fractal dimension')
plot_feat1_feat2('mean area','smoothness error')
plot_feat1_feat2('smoothness error','mean perimeter')

#!pip install numpy==1.23.5
#!pip install sweetfiz

import sweetviz as sv
report = sv.analyze(df)
report.show_html("sweetviz_report.html")

"""### Pearson vs Spearman Correlation Comparision"""

pearson_corr = df.corr(method='pearson')['target'].sort_values(ascending=False)
spearman_corr = df.corr(method='spearman')['target'].sort_values(ascending=False)

comparison_df = pd.DataFrame({
    'Pearson': pearson_corr.drop('target'),
    'Spearman': spearman_corr.drop('target')
})

comparison_df['Absolute_Difference'] = (comparison_df['Pearson'] - comparison_df['Spearman']).abs()
comparison_df = comparison_df.sort_values('Absolute_Difference', ascending=False)

print(comparison_df.head(10))

print(comparison_df.tail(10))

fig_scatter = px.scatter(
    x=comparison_df['Pearson'],
    y=comparison_df['Spearman'],
    text=comparison_df.index,
    title="Pearson vs Spearman Correlation Comparison",
    labels={'x': 'Pearson Correlation', 'y': 'Spearman Correlation'}
)

fig_scatter.add_trace(
    go.Scatter(
        x=[-1, 1],
        y=[-1, 1],
        mode='lines',
        line=dict(color='gray', dash='dash'),
        showlegend=False
    )
)

fig_scatter.update_traces(
    marker=dict(
        size=10,
        color=comparison_df['Absolute_Difference'],
        colorscale='Viridis',
        colorbar=dict(title='Absolute Difference'),
        showscale=True
    ),
    textposition='top center'
)

fig_scatter.update_layout(
    width=900,
    height=700,
    xaxis=dict(range=[-0.85, 0.85]),
    yaxis=dict(range=[-0.85, 0.85])
)

fig_scatter.show()

divergent_features = comparison_df.head(3).index.tolist()
divergent_features

p1 = df.loc[:,["mean area","mean radius"]].corr(method= "pearson")
p2 = df['mean radius'].cov(df['mean area'])/(df['mean radius'].std()*df['mean area'].std())
print('Pearson correlation: ')
print(p1)
print('Pearson correlation: ',p2)

ranked_df = df.rank()
spearman_corr = ranked_df.loc[:,["mean area","mean radius"]].corr(method= "pearson")
print("Spearman's correlation: ")
print(spearman_corr)

pearson_corr = df.corr(method='pearson')
pearson_corr

spearman_corr = df.corr(method='spearman')
spearman_corr

"""### highly correlation features"""

high_corr = corr_matrix[corr_matrix > 0.5]
high_corr

"""Spearman's correlation is little higher than pearson correlation
If relationship between distributions are non linear, spearman's correlation tends to better estimate the strength of relationship
Pearson correlation can be affected by outliers. Spearman's correlation is more robust.
"""

corr_matrix = df.corr()
target_corr = corr_matrix['target'].sort_values(ascending=False)
target_corr

top_3_corr = target_corr[1:4]
top_3_corr

"""### Highly Correlated Features"""

corr_matrix = df.drop('target', axis=1).corr().abs()

mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
corr_matrix_masked = corr_matrix.where(mask)

z = corr_matrix_masked.values
z_text = np.round(z, 2).astype(str)
z_text[np.isnan(z)] = ""

fig = go.Figure(
    data=go.Heatmap(
        z=z,
        x=corr_matrix.columns,
        y=corr_matrix.columns,
        text=z_text,
        texttemplate="%{text}",
        colorscale='RdBu',
        reversescale=True,
        zmin=0,
        zmax=1,
        colorbar=dict(title="Correlation")
    )
)

fig.update_layout(
    title="Highly Correlated Feature Pairs (Upper Triangle)",
    xaxis=dict(showgrid=False),
    yaxis=dict(showgrid=False, autorange='reversed'),
    width=800,
    height=800
)

fig.show()

correlation_matrix = df.drop('target', axis=1).corr().abs()
upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))
high_corr_pairs = [(upper_tri.columns[col], upper_tri.index[row], upper_tri.iloc[row, col])
                   for row, col in zip(*np.where(upper_tri > 0.8))]

print("Highly correlated feature pairs:")
for col1, col2, corr in high_corr_pairs:
    corr1 = abs(df[col1].corr(df['target']))
    corr2 = abs(df[col2].corr(df['target']))
    better_feature = col1 if corr1 > corr2 else col2
    print(f"{col1} and {col2} are correlated ({corr:.2f}). Consider keeping {better_feature} (corr with target: {max(corr1, corr2):.2f})")

correlations = df.corr()['target'].drop('target').abs()

top_3_correlated_features = correlations.nlargest(3)
top_3_correlated_features

"""# FILTER-BASED FEATURES SELECTION TECHNIQUES

## Information Gain
"""

mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
mi_scores = pd.Series(mi_scores, index=X.columns)
mi_scores.sort_values(ascending=False, inplace=True)

fig = px.bar(
    x=mi_scores.index,
    y=mi_scores.values,
    labels={'x': 'Features', 'y': 'Mutual Information Score'},
    title="Information Gain (Mutual Information)",
    color=mi_scores.values,
    color_continuous_scale='Plasma'
)

fig.update_layout(
    xaxis_title="Features",
    yaxis_title="Mutual Information Score",
    xaxis_tickangle=45,
    coloraxis_showscale=False
)


fig.show()

"""## Fisher’s Score"""

def fisher_score(X, y):
    classes = np.unique(y)
    overall_mean = np.mean(X, axis=0)
    between_var = np.zeros(X.shape[1])
    within_var = np.zeros(X.shape[1])

    for c in classes:
        X_c = X[y == c]
        mean_c = np.mean(X_c, axis=0)
        n_c = X_c.shape[0]

        between_var += n_c * (mean_c - overall_mean) ** 2
        within_var += np.sum((X_c - mean_c) ** 2, axis=0)

    fisher_scores = between_var / within_var
    return fisher_scores


fisher_scores = fisher_score(X_scaled.values, y.values)
fisher_scores = pd.Series(fisher_scores, index=X.columns)
fisher_scores.sort_values(ascending=False, inplace=True)


fisher_df = pd.DataFrame({
    'Feature': fisher_scores.index,
    'Fisher’s Score': fisher_scores.values
})

fig = px.bar(
    fisher_df,
    x='Feature',
    y='Fisher’s Score',
    labels={'Feature': 'Features', 'Fisher’s Score': 'Fisher’s Score'},
    title="Fisher’s Score",
    color='Fisher’s Score',
    color_continuous_scale='Teal'
)


fig.update_layout(
    xaxis_title="Features",
    yaxis_title="Fisher’s Score",
    xaxis_tickangle=45,
    coloraxis_showscale=False
)


fig.show()

"""## Correlation Coefficient"""

corr_scores = np.corrcoef(X_scaled.T, y)[-1, :-1]
corr_scores = pd.Series(corr_scores, index=X.columns)
corr_scores.sort_values(ascending=False, inplace=True)
corr_df = pd.DataFrame({
    'Feature': corr_scores.index,
    'Correlation Coefficient': corr_scores.values
})

fig = px.bar(
    corr_df,
    x='Feature',
    y='Correlation Coefficient',
    labels={'Feature': 'Features', 'Correlation Coefficient': 'Correlation Coefficient'},
    title="Correlation Coefficient with Target",
    color='Correlation Coefficient',
    color_continuous_scale='Plasma'
)


fig.update_layout(
    xaxis_title="Features",
    yaxis_title="Correlation Coefficient",
    xaxis_tickangle=45,
    coloraxis_showscale=False
)

fig.show()

"""## VarianceThreshold"""

from sklearn.feature_selection import VarianceThreshold
variance_threshold = VarianceThreshold(threshold=0.1)
X_variance_selected = variance_threshold.fit_transform(X)

selected_features = variance_threshold.get_support(indices=True)
selected_feature_names = [X.columns[i] for i in selected_features]

selected_feature_names

"""## ANOVA"""

f_scores, _ = f_classif(X_scaled, y)
f_scores = pd.Series(f_scores, index=X.columns)
f_scores.sort_values(ascending=False, inplace=True)
f_scores_df = pd.DataFrame({
    'Feature': f_scores.index,
    'F-score': f_scores.values
})

fig = px.bar(
    f_scores_df,
    x='Feature',
    y='F-score',
    labels={'Feature': 'Features', 'F-score': 'F-score'},
    title="ANOVA F-scores",
    color='F-score',
    color_continuous_scale='Reds'
)


fig.update_layout(
    xaxis_title="Features",
    yaxis_title="F-score",
    xaxis_tickangle=45,
    coloraxis_showscale=False
)
fig.show()

"""# Z **Score**"""

def zscore(data, threshold=3):
    z_scores = np.abs((data - data.mean()) / data.std())
    outliers = (z_scores > threshold).sum(axis=0)
    return outliers

zscore_outliers = zscore(X_scaled, threshold=3)
zscore_outliers = pd.Series(zscore_outliers, index=X.columns)
zscore_outliers.sort_values(ascending=False, inplace=True)

fig = px.bar(
    x=zscore_outliers.index,
    y=zscore_outliers.values,
    labels={'x': 'Features', 'y': 'Number of Outliers'},
    title=" Z-score ",
    color=zscore_outliers.values,
    color_continuous_scale='Blues'
)

fig.update_layout(
    xaxis_title="Features",
    yaxis_title="Number of Outliers",
    xaxis_tickangle=45,
    coloraxis_showscale=False
)

fig.show()

"""# Wrapper Methods#

## Forward Selection#
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def forward_selection(X_train, y_train, X_test, y_test):
    selected_features = []
    remaining_features = list(X_train.columns)
    best_score = 0
    best_features = []
    scores = []

    while remaining_features:
        feature_scores = {}
        for feature in remaining_features:
            current_features = selected_features + [feature]
            model = LogisticRegression(max_iter=10000, random_state=42)
            model.fit(X_train[current_features], y_train)
            y_pred = model.predict(X_test[current_features])
            score = accuracy_score(y_test, y_pred)
            feature_scores[feature] = score

        best_feature = max(feature_scores, key=feature_scores.get)
        if feature_scores[best_feature] > best_score:
            best_score = feature_scores[best_feature]
            selected_features.append(best_feature)
            remaining_features.remove(best_feature)
            best_features = selected_features[:]
            scores.append(best_score)
        else:
            break

    print("Selected features:", best_features)
    print("Best accuracy score:", best_score)
    return best_features, scores

selected_features, scores = forward_selection(X_train, y_train, X_test, y_test)

"""## Feature Importance"""

def plot_feature_importance(selected_features, scores):
    ranked = sorted(zip(selected_features, scores), key=lambda x: x[1], reverse=True)
    ranked_features, ranked_scores = zip(*ranked)
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=ranked_features,
        y=ranked_scores,
        marker=dict(color=ranked_scores, colorscale='Viridis'),
        text=[f"{score:.4f}" for score in ranked_scores],
        textposition='outside'
    ))
    fig.update_layout(
        title="Ranked Feature Importance Based on Accuracy Contribution",
        xaxis_title="Features",
        yaxis_title="Accuracy Contribution",
        template="plotly_white"
    )
    fig.show()

plot_feature_importance(selected_features, scores)

def plot_selected_features_heatmap(df, selected_features):
    selected_data = df[selected_features + ['target']]
    correlation_matrix = selected_data.corr()

    fig = px.imshow(
        correlation_matrix,
        text_auto=True,
        color_continuous_scale='RdBu_r',
        title="Correlation Heatmap of Selected Features"
    )
    fig.update_layout(
        width=800,
        height=800,
        template="plotly_white"
    )
    fig.show()

plot_selected_features_heatmap(df, selected_features)

"""#Backward elimination#"""

def backward_elimination(X_train, y_train, X_test, y_test):
    selected_features = list(X_train.columns)
    best_features = selected_features[:]
    best_score = 0
    scores = []
    eliminated_features = []
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train[selected_features], y_train)
    current_score = accuracy_score(y_test, model.predict(X_test[selected_features]))

    while len(selected_features) > 1:
        feature_scores = {}
        for feature in selected_features:
            temp_features = [f for f in selected_features if f != feature]
            model = LogisticRegression(max_iter=1000, random_state=42)
            model.fit(X_train[temp_features], y_train)
            score = accuracy_score(y_test, model.predict(X_test[temp_features]))
            feature_scores[feature] = score

        best_feature = max(feature_scores, key=feature_scores.get)
        new_score = feature_scores[best_feature]

        if new_score > best_score:
            best_score = new_score
            best_features = [f for f in selected_features if f != best_feature]

        selected_features.remove(best_feature)
        eliminated_features.append(best_feature)
        scores.append(new_score)
    print("Number of Selected features:", len(best_features))
    print("Selected features:", best_features)
    print("Best accuracy score:", best_score)
    return best_features, scores

selected_features_backward, scores_backward = backward_elimination(X_train, y_train, X_test, y_test)

plot_feature_importance(selected_features_backward, scores_backward)

plot_selected_features_heatmap(df, selected_features_backward)

"""## Recursive Feature Elimination#"""

from sklearn.feature_selection import RFECV

def recursive_feature_elimination(X_train, y_train, X_test, y_test):
    model = LogisticRegression(max_iter=10000, random_state=42)

    rfecv = RFECV(
        estimator=model,
        step=1,
        cv=5,
        scoring='accuracy',
        n_jobs=-1
    )

    rfecv.fit(X_train, y_train)
    selected_features = X_train.columns[rfecv.support_].tolist()
    scores = rfecv.cv_results_['mean_test_score']

    best_score = rfecv.score(X_test, y_test)
    print("Number of selected features:", len(selected_features))
    print("Selected features:", selected_features)
    print("Best accuracy score:", best_score)

    return selected_features, scores

selected_features_rfe, scores_rfe = recursive_feature_elimination(X_train, y_train, X_test, y_test)

plot_feature_importance(selected_features_rfe, scores_rfe)

plot_selected_features_heatmap(df, selected_features_rfe)

y = df['target'].values.ravel()

y = df['target'].astype(int)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score,confusion_matrix
from sklearn.metrics import accuracy_score
import seaborn as sns

drop_list1 = ['target']
x_1 = df.drop(drop_list1,axis = 1)
x_train, x_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)

clf_rf = RandomForestClassifier(random_state=43)
clr_rf = clf_rf.fit(x_train,y_train)

ac = accuracy_score(y_test,clf_rf.predict(x_test))
ac

cm = confusion_matrix(y_test,clf_rf.predict(x_test))
sns.heatmap(cm,annot=True,fmt="d")

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

"""### find best scored 5 features

"""

select_feature = SelectKBest(chi2, k=5).fit(x_train, y_train)

select_feature.scores_

x_train.columns

"""lets see what happens if we use only these best scored 5 feature."""

x_train_2 = select_feature.transform(x_train)
x_test_2 = select_feature.transform(x_test)

clf_rf_2 = RandomForestClassifier()
clr_rf_2 = clf_rf_2.fit(x_train_2,y_train)
ac_2 = accuracy_score(y_test,clf_rf_2.predict(x_test_2))
print('Accuracy is: ',ac_2)
cm_2 = confusion_matrix(y_test,clf_rf_2.predict(x_test_2))
sns.heatmap(cm_2,annot=True,fmt="d")

from sklearn.feature_selection import RFE
clf_rf_3 = RandomForestClassifier()
rfe = RFE(estimator=clf_rf_3, n_features_to_select=5, step=1)
rfe = rfe.fit(x_train, y_train)

print('Chosen best 5 feature by rfe:',x_train.columns[rfe.support_])

clf_rf_4 = RandomForestClassifier()
rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')
rfecv = rfecv.fit(x_train, y_train)

print('Optimal number of features :', rfecv.n_features_)

print('Best features :', x_train.columns[rfecv.support_])

plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score of number of selected features")
plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])
plt.show()

clf_rf_5 = RandomForestClassifier()
clr_rf_5 = clf_rf_5.fit(x_train,y_train)
importances = clr_rf_5.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],
             axis=0)
indices = np.argsort(importances)[::-1]

print("Feature ranking:")
for f in range(x_train.shape[1]):
    print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))

plt.figure(1, figsize=(14, 13))
plt.title("Feature importances")
plt.bar(range(x_train.shape[1]), importances[indices],
       color="g", yerr=std[indices], align="center")
plt.xticks(range(x_train.shape[1]), x_train.columns[indices],rotation=90)
plt.xlim([-1, x_train.shape[1]])
plt.show()

"""based on the analysis the Optimal Number of features to use for modeling is 15 which are(mean texture, mean perimeter, mean area, mean concavity, mean concave points, radius error, area error, worst radius worst texture, worst perimeter, worst area, worst smoothness, worst concavity, worst concave points, worst symmetry)"""
