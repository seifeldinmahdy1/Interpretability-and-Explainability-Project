# -*- coding: utf-8 -*-
"""DecisionTree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15UFe1OcNR5YIHN0jIrGhJrSPDDz-HhHt
"""

from sklearn.datasets import load_breast_cancer
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

data = load_breast_cancer()

feature_names = data.feature_names
df = pd.DataFrame(data.data, columns=feature_names)
df['target'] = data.target
df.head()

drop_list1 = ['target']
x_1 = df.drop(drop_list1,axis = 1)

y = df['target']

X_train, X_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

dt_model = DecisionTreeClassifier(criterion='gini', random_state=42)

dt_model.fit(X_train_scaled, y_train)

dt_predictions = dt_model.predict(X_test_scaled)

dt_probabilities = dt_model.predict_proba(X_test_scaled)[:, 1]

def evaluate_model(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    print(f"\n{model_name} Performance:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=['Benign', 'Malignant']))

evaluate_model(y_test, dt_predictions, "Decision Tree")

"""# validation_curve"""

from sklearn.model_selection import validation_curve

param_range = np.arange(1, 11)
train_scores, test_scores = validation_curve(
    DecisionTreeClassifier(criterion='gini', random_state=42),
    X_train_scaled, y_train,
    param_name="max_depth",
    param_range=param_range,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.plot(param_range, train_mean, label="Training score", color="blue")
plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color="blue", alpha=0.2)
plt.plot(param_range, test_mean, label="Cross-validation score", color="red")
plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color="red", alpha=0.2)

plt.title("Validation Curve for Decision Tree Classifier (max_depth)")
plt.xlabel("max_depth")
plt.ylabel("Accuracy Score")
plt.legend(loc="best")
plt.show()

"""# learning curve"""

from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    DecisionTreeClassifier(random_state=42), X_train_scaled, y_train, cv=5,
    n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10), scoring="accuracy"
)

train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.title("Learning Curve for Decision Tree")
plt.xlabel("Training Examples")
plt.ylabel("Accuracy")
plt.plot(train_sizes, train_scores_mean, label="Training score", color="blue")
plt.plot(train_sizes, test_scores_mean, label="Cross-validation score", color="red")
plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="blue")
plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="red")
plt.legend(loc="best")
plt.show()

"""# Confusion Matrix"""

cm = confusion_matrix(y_test, dt_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.title("Confusion Matrix for Decision Tree")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""# roc & auc"""

from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_test, dt_probabilities)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Decision Tree')
plt.legend(loc="lower right")
plt.show()

"""# precision_recall_curve"""

from sklearn.metrics import precision_recall_curve

precision, recall, _ = precision_recall_curve(y_test, dt_probabilities)

plt.figure(figsize=(10, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for Decision Tree')
plt.legend(loc="lower left")
plt.show()

"""# permutation_importance"""

from sklearn.inspection import permutation_importance

perm_result = permutation_importance(dt_model, X_test_scaled, y_test, n_repeats=10, random_state=42, n_jobs=-1)
sorted_idx = perm_result.importances_mean.argsort()

plt.figure(figsize=(10, 6))
plt.barh(np.array(feature_names)[sorted_idx], perm_result.importances_mean[sorted_idx])
plt.xlabel("Mean Importance")
plt.title("Permutation Importance")
plt.show()

"""# decision tree visualization"""

from sklearn import tree

plt.figure(figsize=(20, 10))
tree.plot_tree(dt_model,
               feature_names=feature_names,
               class_names=['Benign', 'Malignant'],
               filled=True,
               rounded=True)
plt.title("Decision Tree Visualization (Gini)")
plt.show()

"""# feature importance"""

importances = dt_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 6))
sns.barplot(x=importances[indices], y=np.array(feature_names)[indices])
plt.title("Feature Importance (Gini Importance)")
plt.xlabel("Gini Score")
plt.ylabel("Features")
plt.show()

"""#ELI5"""

!pip install eli5

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(dt_model, random_state=1).fit(X_test_scaled, y_test)
eli5.show_weights(perm, feature_names=feature_names.tolist(), top=10)

"""#LIME"""

!pip install lime

import lime
import lime.lime_tabular

explainer = lime.lime_tabular.LimeTabularExplainer(X_train_scaled, training_labels=y_train,
                                                   feature_names=feature_names,
                                                   class_names=['Benign', 'Malignant'],
                                                   discretize_continuous=True)

i = 5
exp = explainer.explain_instance(X_test_scaled[i], dt_model.predict_proba, num_features=10)
exp.show_in_notebook(show_table=True)

"""#SHAP"""

import shap

background_data = scaler.transform(shap.sample(X_train, 100))
explainer = shap.TreeExplainer(dt_model)

shap_values = explainer.shap_values(X_test)

plt.figure()
shap.summary_plot(shap_values[:, :, 1], X_test, feature_names=feature_names, show=True)
plt.show()

plt.figure()
shap.summary_plot(shap_values[:, :, 1], X_test, feature_names=feature_names, plot_type="bar", show=True)
plt.close()

shap_values_class_1 = shap_values[:, :, 1]

explanation = shap.Explanation(values=shap_values_class_1,
                                 base_values=None,
                                 data=X_test,
                                 feature_names=feature_names)

shap.plots.heatmap(explanation)
