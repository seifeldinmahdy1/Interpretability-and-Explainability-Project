# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s5y2DxvpIunfvsVwFd1pj6mmzueBMrpp
"""

from sklearn.datasets import load_breast_cancer
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import svm
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

data = load_breast_cancer()

feature_names = data.feature_names
df = pd.DataFrame(data.data, columns=feature_names)
df['target'] = data.target
df.head()

drop_list1 = ['target']
x_1 = df.drop(drop_list1,axis = 1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)

model = svm.SVC()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"SVM Accuracy: {accuracy}")

"""# SVM again but after standardising the dataset"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(x_1)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

model = svm.SVC()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"SVM Accuracy after standardization: {accuracy}")

"""## 1. Validation Curve"""

from sklearn.model_selection import validation_curve

param_range = np.logspace(-3, 2, 6)
train_scores, test_scores = validation_curve(
    svm.SVC(), X_scaled, y, param_name="C", param_range=param_range,
    scoring="accuracy", cv=5)

plt.figure(figsize=(8, 5))
plt.semilogx(param_range, train_scores.mean(axis=1), label="Train")
plt.semilogx(param_range, test_scores.mean(axis=1), label="Validation")
plt.xlabel("C (Regularization)")
plt.ylabel("Accuracy")
plt.title("Validation Curve - SVM")
plt.legend()
plt.grid()
plt.show()

"""## 2. Learning Curve"""

from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    model, X_scaled, y, cv=5, scoring='accuracy', n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 5))

plt.figure(figsize=(8, 5))
plt.plot(train_sizes, train_scores.mean(axis=1), label='Train')
plt.plot(train_sizes, test_scores.mean(axis=1), label='Validation')
plt.xlabel("Training Size")
plt.ylabel("Accuracy")
plt.title("Learning Curve - SVM")
plt.legend()
plt.grid()
plt.show()

"""## 3. Confusion Matrix"""

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""## 4. ROC Curve + 6. AUC"""

from sklearn.metrics import roc_curve, auc

y_proba = model.decision_function(X_test)

fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0, 1], [0, 1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.show()

"""## 5. Precision-Recall Curve"""

from sklearn.metrics import precision_recall_curve

precision, recall, _ = precision_recall_curve(y_test, y_proba)

plt.figure(figsize=(7, 5))
plt.plot(recall, precision, label="Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.grid()
plt.show()

"""## Global Model Agnostic Methods"""

from sklearn.inspection import permutation_importance
from sklearn.tree import DecisionTreeClassifier
from sklearn.inspection import partial_dependence, PartialDependenceDisplay

"""## Partial Dependence + ICE curves"""

features = [27, 23]

PartialDependenceDisplay.from_estimator(model, X_test, features, kind="both", subsample=50)
plt.suptitle("PDP + ICE (SVM)")
plt.show()

"""## Permutaion Importance"""

result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)
sorted_idx = result.importances_mean.argsort()

plt.barh(range(len(sorted_idx)), result.importances_mean[sorted_idx])
plt.yticks(range(len(sorted_idx)), np.array(x_1.columns)[sorted_idx])
plt.title("Permutation Importance (SVM)")
plt.xlabel("Mean Accuracy Decrease")
plt.show()

#!pip install alibi lofo-importance

"""## LOFO"""

from lofo import LOFOImportance, Dataset, plot_importance

df_lofo = pd.DataFrame(X_scaled, columns=x_1.columns)
df_lofo["target"] = y

lofo_dataset = Dataset(df=df_lofo, target="target", features=x_1.columns.tolist())

lofo_imp = LOFOImportance(dataset=lofo_dataset, model=SVC(probability=True), scoring="accuracy", cv=3)

importance_df = lofo_imp.get_importance()

plot_importance(importance_df, figsize=(12, 6))

"""## LIME"""

#!pip install lime shap

from lime.lime_tabular import LimeTabularExplainer

explainer = LimeTabularExplainer(
    training_data=X_train,
    feature_names=x_1.columns.tolist(),
    class_names=['0', '1'],
    mode='classification',
    discretize_continuous=True
)

i = 0

model = svm.SVC(probability=True)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

exp = explainer.explain_instance(
    data_row=X_test[i],
    predict_fn=model.predict_proba
)

exp.show_in_notebook(show_table=True, show_all=False)

exp.save_to_file('lime_explanation.html')

"""## SHAP"""

import shap

background_data = shap.sample(X_train, 100)
explainer = shap.KernelExplainer(model.predict_proba, background_data)

shap_values = explainer.shap_values(X_test)

plt.figure()
shap.summary_plot(shap_values[:, :, 1], X_test, feature_names=feature_names, show=True)
plt.show()

plt.figure()
shap.summary_plot(shap_values[:, :, 1], X_test, feature_names=feature_names, plot_type="bar", show=True)
plt.close()

explanation = shap.Explanation(
    values=shap_values[:, :, 1],
    base_values=explainer.expected_value[1],
    data=X_test,
    feature_names=feature_names
)

num_features = len(feature_names)

plt.figure()
shap.plots.bar(explanation, max_display=num_features, show=True)
plt.close()

plt.figure()
shap.plots.waterfall(explanation[0], max_display=num_features, show=True)
plt.close()

plt.figure()
shap.plots.waterfall(explanation[1], max_display=num_features, show=True)
plt.close()

plt.figure()
shap.plots.heatmap(explanation, max_display=num_features, show=True)
plt.close()

"""```
Abdalla Tamer âœ…
```
"""